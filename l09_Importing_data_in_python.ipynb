{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2ng/RtoSOzfuLFvTGQHAF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imppel-9704/de_track_datacamp/blob/main/Importing_data_in_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing data\n",
        "- Flat files e.g. .txt, .csv\n",
        "- Files from other software. (Excel spreadsheet, Stata, SAS and MATLAB files.)\n",
        "- Relational database.\n",
        "\n",
        "## Reading a text file\n",
        "```\n",
        "filename = 'huck_finn.txt'\n",
        "file = open(filename, mode='r') # 'r' is to read\n",
        "text = file.read()\n",
        "file.close()\n",
        "\n",
        "# then can print to check it\n",
        "print(text)\n",
        "```\n",
        "\n",
        "## Writting to a file\n",
        "```\n",
        "filename = 'huck_finn.txt'\n",
        "file = open(filename, mode='w') # 'w' is to write\n",
        "file.close()\n",
        "```\n",
        "\n",
        "## Avoiding to close the connection to the file\n",
        "```\n",
        "with open('huck_finn.txt', 'r') as file:\n",
        "  print(file.read())\n",
        "```\n",
        "\n",
        "## Practice\n",
        "```\n",
        "# Read & print the first 3 lines\n",
        "with open('moby_dick.txt') as file:\n",
        "  print(file.readline())\n",
        "  print(file.readline())\n",
        "  print(file.readline())\n",
        "```\n",
        "\n",
        "## Flat files\n",
        "- Text files containing records.\n",
        "- That is, table data.\n",
        "- Record: row of fields or attributes.\n",
        "- Column: feature or attributes. (column names.)\n",
        "\n",
        "*File extension*\n",
        "- .csv - comma separated values.\n",
        "- .txt - text file.\n",
        "- Values in flat files can be separated by commas or tabs - delimiters."
      ],
      "metadata": {
        "id": "G5JjjrBrlAzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing flat files using NumPy\n",
        "\n",
        "## Why Numpy?\n",
        "- Numpy arrays: stadard for storing numerical data. (fast and clean.)\n",
        "- Essential for other package e.g. scikit-learn (ml package for python.)\n",
        "- Have numer built-in function (easier and efficient for import data as array.)\n",
        "  - loadtxt()\n",
        "  - genfromtxt()\n",
        "\n",
        "## Importing flat files using Numpy\n",
        "```\n",
        "import numpy as np\n",
        "filename = 'MNIST.txt'\n",
        "data = np.loadtext(filename, delimiter=',')\n",
        "data\n",
        "```\n",
        "\n",
        "## Customizing Numpy import\n",
        "```\n",
        "import numpy as np\n",
        "filename = 'MNIST_head.txt'\n",
        "data = np.loadtext(filename, delimiter=',', skiprows=1)\n",
        "print(data)\n",
        "```\n",
        "\n",
        "```\n",
        "# Import numpy\n",
        "import numpy as np\n",
        "\n",
        "# Assign the filename: file\n",
        "file = 'digits_header.txt'\n",
        "\n",
        "# Load the data: data\n",
        "# Skip the first skiprows lines, including comments; default: 0.\n",
        "# usecols takes a list of the indices of the columns you wish to keep.\n",
        "data = np.loadtxt(file, delimiter='\\t', skiprows=1, usecols=[0, 2])\n",
        "\n",
        "# Print data\n",
        "print(data)\n",
        "```\n",
        "\n",
        "## Importing .csv files using Numpy\n",
        "```\n",
        "# Import 'titanic.csv' using the function np.genfromtxt()\n",
        "\n",
        "data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)\n",
        "```\n",
        "\n",
        "```\n",
        "# Assign the filename: file\n",
        "file = 'titanic.csv'\n",
        "\n",
        "# Import file using np.recfromcsv: d\n",
        "d = np.recfromcsv(file, delimiter=',', dtype=None)\n",
        "\n",
        "# Print out first three entries of d\n",
        "print(d[:3])\n",
        "\n",
        "```\n",
        "\n",
        "## Importing .csv files using Pandas\n",
        "\n",
        "## Manipulating pandas DataFrames\n",
        "- Exploratory data analysis.\n",
        "- Data wragling.\n",
        "- Data preprocessing.\n",
        "- Building models.\n",
        "- Visualization.\n",
        "- Standard and best practice to use Pandas.\n",
        "\n",
        "```\n",
        "# Import pandas as pd\n",
        "import pandas as pd\n",
        "\n",
        "# Assign the filename: file\n",
        "file = 'titanic.csv'\n",
        "\n",
        "# Read the file into a DataFrame: df\n",
        "df = pd.read_csv(file)\n",
        "\n",
        "# View the head of the DataFrame\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "```\n",
        "# Assign the filename: file\n",
        "file = 'digits.csv'\n",
        "\n",
        "# Read the first 5 rows of the file into a DataFrame: data\n",
        "data = pd.read_csv(file, nrows=5, header=None)\n",
        "\n",
        "# Build a numpy array from the DataFrame: data_array\n",
        "data_array = np.array(data)\n",
        "\n",
        "# Print the datatype of data_array to the shell\n",
        "print(type(data_array))\n",
        "```\n",
        "\n",
        "```\n",
        "# Import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assign filename: file\n",
        "file = 'titanic_corrupt.txt'\n",
        "\n",
        "# Import file: data\n",
        "data = pd.read_csv(file, sep='\\t', comment='#', na_values='Nothing')\n",
        "\n",
        "# Print the head of the DataFrame\n",
        "print(data.head())\n",
        "\n",
        "# Plot 'Age' variable in a histogram\n",
        "pd.DataFrame.hist(data[['Age']])\n",
        "plt.xlabel('Age (years)')\n",
        "plt.ylabel('count')\n",
        "plt.show()\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "vIeMEpa4n1jJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to other file types.\n",
        "- Excel spreadsheet.\n",
        "- MATLAB files.\n",
        "- SAS.\n",
        "- Stata files.\n",
        "- HDF5 files.\n",
        "\n",
        "## Pickled files\n",
        "- file type native to Python.\n",
        "- Motivation: many datatype for which it isn't obvious how to store them.\n",
        "- Pickled files are serialized.\n",
        "- Serialize = convert object to bytestream.\n",
        "\n",
        "```\n",
        "# Import pickle package\n",
        "import pickle\n",
        "\n",
        "# Open pickle file and load data: d\n",
        "with open('data.pkl', 'rb') as file:\n",
        "    d = pickle.load(file)\n",
        "\n",
        "# Print d\n",
        "print(d)\n",
        "\n",
        "# Print datatype of d\n",
        "print(type(d))\n",
        "\n",
        "##output\n",
        "{'June': '69.4', 'Aug': '85', 'Airline': '8', 'Mar': '84.4'}\n",
        "<class 'dict'>\n",
        "```\n",
        "\n",
        "## Excel spreadsheet\n",
        "```\n",
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Assign spreadsheet filename: file\n",
        "file = 'battledeath.xlsx'\n",
        "\n",
        "# Load spreadsheet: xls\n",
        "xls = pd.ExcelFile(file)\n",
        "\n",
        "# Print sheet names\n",
        "print(xls.sheet_names)\n",
        "\n",
        "##output\n",
        "['2002', '2004']\n",
        "```\n",
        "\n",
        "```\n",
        "# Load a sheet into a DataFrame by name: df1\n",
        "df1 = xls.parse('2004')\n",
        "\n",
        "# Print the head of the DataFrame df1\n",
        "print(df1.head())\n",
        "\n",
        "# Load a sheet into a DataFrame by index: df2 (Load first sheet using index)\n",
        "df2 = xls.parse(0)\n",
        "\n",
        "# Print the head of the DataFrame df2\n",
        "print(df2.head())\n",
        "```\n",
        "\n",
        "```\n",
        "# Parse the first sheet and rename the columns: df1\n",
        "df1 = xls.parse(0, skiprows=[0], names=['Country', 'AAM due to War (2002)'])\n",
        "\n",
        "# Print the head of the DataFrame df1\n",
        "print(df1.head())\n",
        "\n",
        "# Parse the first column of the second sheet and rename the column: df2\n",
        "df2 = xls.parse(1, usecols=[0], skiprows=[0], names=['Country'])\n",
        "\n",
        "# Print the head of the DataFrame df2\n",
        "print(df2.head())\n",
        "```\n"
      ],
      "metadata": {
        "id": "8nOieJVR0w18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing SAS/Stata files using pandas\n",
        "\n",
        "## SAS and Stata files\n",
        "- SAS: Statistic Analsis System\n",
        "- Stata: \"Statistic\" + \"data\"\n",
        "- SAS: The former is used a great deal in business analytics and biostatistics.\n",
        "- Stata: Popular in academic social science research.\n",
        "\n",
        "*SAS files*\n",
        "- Used for:\n",
        "  - Advanced analytics.\n",
        "  - Multivariate analysis.\n",
        "  - Business intelligence.\n",
        "  - Data management.\n",
        "  - Predictive analytics.\n",
        "  - Standard for computational analysis.\n",
        "\n",
        "```\n",
        "# Importing SAS files\n",
        "import pandas as pd\n",
        "from sas7bdat import SAS7BDAT\n",
        "with SAS7BDAT('urbanpop.sas7bdat') as file:\n",
        "  df_sas = file.to_data_frame()\n",
        "```\n",
        "\n",
        "```\n",
        "# Importing Stata files\n",
        "import pandas as pd\n",
        "data = pd.read_stata('urbanpop.dta')\n",
        "```"
      ],
      "metadata": {
        "id": "EbhGpWXZ6toS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing HDF5 files\n",
        "\n",
        "## HDF5\n",
        "- Hierarchical Data Format version 5\n",
        "- Standard for storing large quantities of numerical data.\n",
        "- Datasets can be hundreds of gigabytes or terabytes.\n",
        "- HDF5 can scale to exabytes.\n",
        "\n",
        "```\n",
        "# Importing HDF5 files\n",
        "import h5py\n",
        "filename = 'H-H1_LOSC_4_V1_815411200-4096.hdf5'\n",
        "data = h5py.File(filename, 'r') # 'r' is to read\n",
        "\n",
        "for key in data.keys():\n",
        "  print(key) # There are 3 keys: meta, quality, strain\n",
        "\n",
        "for key in data['meta'].keys():\n",
        "  print(key)\n",
        "  print(np.array(data['meta']['Description']), np.array(data['meta']['Detector']))\n",
        "```"
      ],
      "metadata": {
        "id": "B7nb_b_J9sKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing MATLAB files\n",
        "\n",
        "## MATLAB\n",
        "- \"Matrix Laboratory\"\n",
        "- Industry standard in engineering and science.\n",
        "- Data saves as .mat files.\n",
        "\n",
        "## SciPy to the rescue\n",
        "- scipy.io.loadmat() - read .mat files.\n",
        "- scipy.io.savemat() - write .mat files.\n",
        "\n",
        "```\n",
        "# Importing .mat files\n",
        "import scipy.io\n",
        "filename = \"workspace.mat\"\n",
        "mat = scipy.io.loadmat(filename)\n",
        "print(type(mat))\n",
        "## output\n",
        "<class 'dict'>\n",
        "```\n",
        "\n",
        "- keys = MATLAB variable names.\n",
        "- values = objects assigned to variables.\n",
        "\n",
        "```\n",
        "print(type(mat['x']))\n",
        "## output\n",
        "<class 'numpy.ndarray'>\n",
        "```"
      ],
      "metadata": {
        "id": "Mni69rUwABwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to relational databases\n",
        "## The relational model\n",
        "- Each row or record in a table represents an instance of an entity type.\n",
        "- Each column in a table represents an attribute or feature of an instance.\n",
        "- Every table contains a primary key column, which has a unique entry for each row.\n",
        "\n",
        "## Creating a database engine in Python\n",
        "Choosing to useSQLite database. (Fast and Simple)\n",
        "\n",
        "Library to connect with SQLite is \"SQLAlchemy\"\n",
        "```\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "# Save the table names to a list: table_names\n",
        "table_names = engine.table_names()\n",
        "\n",
        "# Print the table names to the shell\n",
        "print(table_names))\n",
        "```\n",
        "Function create_engine will communicate with our queries to the database."
      ],
      "metadata": {
        "id": "hkdmBm5elOc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workflow of SQL querying\n",
        "1. Import packages and functions.\n",
        "2. Create the database engine.\n",
        "3. Connect to the engine.\n",
        "4. Query the database.\n",
        "5. Save query results to a DataFrame.\n",
        "6. Close connection.\n",
        "\n",
        "Example:\n",
        "```\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "engine = create_engine('sqlite:///chinook.sqlite')\n",
        "con = engine.connect()\n",
        "rs = con.execute(\"SELECT * FROM table_name\")\n",
        "df = pd.DataFrame(rs.fetchall())\n",
        "con.close()\n",
        "```\n",
        "\n",
        "Using the context manager:\n",
        "```\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "engine = create_engine('sqlite:///chinook.sqlite')\n",
        "\n",
        "with engine.con() as con:\n",
        "  rs = con.execute(\"SELECT * FROM table_name\")\n",
        "  df = pd.DataFrame(rs.fetchmany(size=5)) # size=5 means imports 5 rows\n",
        "  df.columns = rs.keys()\n",
        "```\n",
        "\n",
        "```\n",
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Open engine connection: con\n",
        "con = engine.connect()\n",
        "\n",
        "# Perform query: rs\n",
        "rs = con.execute(\"SELECT * FROM Album\")\n",
        "\n",
        "# Save results of the query to DataFrame: df\n",
        "df = pd.DataFrame(rs.fetchall())\n",
        "\n",
        "# Close connection\n",
        "con.close()\n",
        "\n",
        "# Print head of DataFrame df\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Perform query and save results to DataFrame: df\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute(\"SELECT LastName, Title FROM Employee\")\n",
        "    df = pd.DataFrame(rs.fetchmany(size=3))\n",
        "    df.columns = rs.keys()\n",
        "\n",
        "# Print the length of the DataFrame df\n",
        "print(len(df))\n",
        "\n",
        "# Print the head of the DataFrame df\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "## Querying relational databases directly with pandas\n",
        "\n",
        "```\n",
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "df = pd.read_sql_query(\"SELECT * FROM Orders\", engine)\n",
        "```\n",
        "\n",
        "## INNER JOIN in Python (Pandas)\n",
        "```\n",
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Perform query and save results to DataFrame: df\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute(\"SELECT Title, Name FROM Album INNER JOIN Artist ON Album.ArtistId = Artist.ArtistId\")\n",
        "    df = pd.DataFrame(rs.fetchall())\n",
        "    df.columns = rs.keys()\n",
        "\n",
        "# Print head of DataFrame df\n",
        "print(df.head())\n",
        "```"
      ],
      "metadata": {
        "id": "fyE7DPS_pCsA"
      }
    }
  ]
}